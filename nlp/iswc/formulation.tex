\subsection{Problem definition}
Consider an unstructured document (equivalently denoted \emph{raw text}). We assume that a set of $p$ \emph{mentions} $M=\{m_1,m_2\ldots m_p\}$ can be extracted from each such document, where each \emph{mention} is defined as a fragment of text that occurs somewhere in the body of the text. Intuitively, each mention describes an entity. In practice, note that $p$ is unknown and the extraction process is imperfect. Also assume a simplified (but still accurate) representation of the Wikipedia knowledge base as a set of $T$ \emph{links} $L=\{t_1,t_2\ldots t_T\}$. For the purposes of this section, we assume $T$ is a constant. In reality, T is a function of underlying variables like \emph{time} and \emph{language}. In the rest of the work, we assume the English language, though the techniques can be applied to other languages for which the API can be invoked. 

There are two tasks that now need to be undertaken, \emph{ranking} and \emph{linking}. Ranking assumes that some underlying system\footnote{The Wikipedia API, for example, but also offline systems previously proposed in the literature} is able to generate a set of \emph{candidate links} for a given mention $m$ (we drop the subscript for ease of exposition). Let this candidate set be $L'_m \subseteq L$. Intuitively, such a candidate set represents candidates for disambiguating the mention. The goal of ranking is to turn this set into an ordered list, based on some ranking algorithm. Since the original paper \cite{bunescu}, techniques have relied primarily on machine learning. We explicitly assume that each mention has \emph{at most} one correct candidate disambiguation. A \emph{k-correct} ranking would then place the correct candidate disambiguation (if it exists) in the top $k$. 

Linking is a \emph{binary} classification problem that takes as input a mention and a \emph{single} candidate disambiguation (usually output by the ranker) and with the help of contextual features, decides whether the candidate disambiguation is the correct one. Although linking might seem easier than ranking, it was empirically shown to be quite difficult in practice, even in the supervised setting \cite{roth}. The reason is that contextual features can be misleading with respect to \emph{nulls}. That is, it is difficult to tell when \emph{not} to link a candidate. Accuracy was often driven down by \emph{false negatives} \cite{roth}.

In this paper, we are exclusively concerned with the \emph{unsupervised linking} problem. As described subsequently, we use a conservative approach that allows us to bypass ranking the candidate links returned by the Wikipedia API. This enables us to focus our resources primarily on the more difficult problem of linking. 
\subsection{Features}
In recent state-of-the-art systems, ranking and linking make use of both global and local features. For ranking, assume that we have a set $L'_m$ of candidate links for all mentions $m \in M$. The ranking of each list can either occur independently of each other (local) or be dependent on each other (global). The global optimization was shown to be NP-hard \cite{roth}. For linking, an analogous procedure applies. Clearly, global methods are expensive but have higher accuracy if we assume the documents to have thematic coherence. This assumption is problematic if the document has variety in its descriptions. We explore the role of different features empirically in Section \ref{experiments}.