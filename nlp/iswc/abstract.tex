Over the last decade, Wikipedia has emerged as the \emph{de facto} global knowledge base owing to its exponential growth in popularity. At the same time, there are many unstructured documents on the Web that can be \emph{enriched} by recognizing \emph{entities} within the document and linking them to specific pages in Wikipedia. Recent approaches have tackled this problem by exploiting global and local feature engineering methods on Wikipedia \emph{dumps}. These approaches are supervised, in that they require training on manually provided data before they can disambiguate links to unknown entities. While useful in many contexts, such methods lack two features. The first is the ability to perform instantaneous and therefore, \emph{online}, wikification in articles that are published and consumed in real-time. An example of a use-case would be a breaking news article.
As a new article is written about a breaking news event, it would be possible to 
augment the text via links to specific pages in wikipedia.
The second is \emph{automation}, since online wikification is likely to be useful in an unsupervised setting due to the evolving nature of the Web. The problem is exacerbated by regular updates and additions to Wikipedia; hence, a dump cannot always be relied upon for either of the two goals stated. In this paper, we present a solution to both these problems by making judicious use of the Wikipedia API and favoring precision over recall. To control complexity and simplify implementation, we use simple, but discriminative features. 
Experimental results on a test dataset used in a prior offline approach demonstrate that, in conjunction with the Wikipedia API, the best features can achieve over 80 percent accuracy on the online wikification task.  
\keywords{Wikification, Entity Linking}
